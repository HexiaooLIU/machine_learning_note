1, $Y_{ji}$ 表示样本 $x_j$ 属于第i个高斯混合成分的概率，因此可表示为 $p(\theta=i|x_j)$ .

由此 $Y_{ji}=p(\theta=i|x_j)=\frac{\alpha_i8p(x_j|\mu_i, \sum_i)}{\sum_{i=1}^N\alpha_i8p(x_j|\mu_i, \sum_i)}$ 得到(13.5)

对对数似然  $LL(D_l\cup D_u)$ 分别求关于 $\mu_i$、$\sum_i$、$\alpha_i$的偏导，并分别使偏导=0，即可求得(13.6)(13.7)(13.8)的三个式子

2, `https://blog.csdn.net/qilixuening/article/details/72810579`

3,
由
$$ \log L=\sum_{x_i\in X}\log \sum^L_{l=1} \alpha_lf(x_i/\theta_l)+\sum_{x_i\in X}\log \sum^L_{l=1} \alpha_lP(c_i/x_i,m_i=l)f(x_i/\theta_l)$$
设
$$P(c_i/m_i,x_i)=P(c_i/m_i)\equiv\beta_{c_i|j}$$
得
$$P(c_i/x_i)=\sum_j(\frac{\alpha_jf(x_i/\theta_j)}{\sum_l\alpha_jf(x_i/\theta_j)})\beta_{c_i|j}$$
由此可得混合专家模式方法中 $\mu_j^{(t+1)}$, $\\Sigma_j^{(t+1)}$, $\alpha_j^{(t+1)}$ 的更新公式
$$\mu_j^{(t+1)}=\frac{1}{N\alpha_j^{(t)}}(\sum_{x_i\in X}x_iP(m_i=j/x_i,c_i,\theta^{(t)})+\sum_{x_i\in X}x_iP(m_i=j/x_i,\theta^{(t)}))$$

$$\Sigma_j^{(t+1)}=\frac{1}{N\alpha_j^{(t)}}(\sum_{x_i\in X}S_{ij}^{(t)}P(m_i=j/x_i,c_i,\theta^{(t)})+\sum_{x_i\in X}S_{ij}^{(t)}P(m_i=j/x_i,\theta^{(t)}))$$

$$\alpha_j^{(t+1)}=\frac{1}{N}(\sum_{x_i\in X}P(m_i=j/x_i,c_i,\theta^{(t)})+\sum_{x_i\in X}P(m_i=j/x_i,\theta^{(t)}))$$
以及
$$\beta_{k/j}^{(t+1)}=\frac{1}{N\alpha_j^{(t)}}(\sum_{x_i\in X\cap c_i=k}P(m_i=j/x_i,c_i,\theta^{(t)})+\sum_{x_i\in X\cap c_i=k}P(m_i=j/x_i,\theta^{(t)}))$$

Reference:  Miller, D. J., and Uyar, H. S. 1997. A mixture of experts classifier with learning based on both labelled and unlabelled data. In NIPS 9.

6, 在标记调整过程中，每次讲最有可能指派错误的样本进行调整，即正负伪标记样本中松弛变量最大且大于1的样本进行标记更改，可以减少迭代的次数

7, 将新样本作为无标记样本再次进行图半监督算法
8, 训练样本远少于无标记样本，若将全部样本上进行训练，很多无标记样本会成为噪声，从而影响训练效果。应进行局部伪标记调整来优化分类器
