1， 用文字描述吧，不画了orz
条件随机场：N个变量x均依赖y：y指向x，x在框N中
朴素贝叶斯分类器：y依赖于所有x变量：y指向x，xy都在框N中

2，设 $v\in V$是无向图G中任意一点，W是与v有边连接的所有节点，O是v,W以外的其他所有节点，v表示的随机变量是 $Y_W$， W表示的随机变量组是 $Y_W$， O表示的是随机变量组是 $Y_O$。局部马尔科夫性是指在给定随机变量组 $Y_W$ 的条件下随机变量 $Y_v$ 与随机变量组 $Y_O$ 是独立的，即 $P(Y_v,Y_O|Y_W)=P(Y_v|Y_W)P(Y_O|Y_W)$， 在 $P(Y_O|Y_W)>0$时，等价地 $P(Y_v|Y_W)=P(Y_v|Y_W,Y_O)$

(参考《统计学习方法》P192)

3， 对于两个非邻接变量A和C，一定存在A的所有邻接变量集合的子集B把AC分离，即AC独立，可说明局部 马尔科夫性

4， 极大团的势函数可以看成是所有子团势函数的联合分布，再乘上规范化因子使得ψ(x)是正确的概率。

5， 同：都是判别式模型，学习条件概率分布P(Y|X)

条件随机场可以有对个输出变量 $y_1,y_2,y_3,\dots y_N$ : $P(y_1,y_2,y_3,\dots y_N|x)=\frac1Z\prod_C\Psi_C(Y_C,x)$

对率回归只有一个输出变量y：$P(y|x)=\frac1Ze^{(Wx+b)y}=\frac1Z\Psi(y,x)$

因此可以把对率回归看作是条件随机场的一种特殊情况

6， 对极大团计算概率累加时要对每部所有变量同事进行累加，需要计算的次数是 $\prod$， 指数级的；而单独增加节点数目，需要计算的次数可能是 $\sum$,因此未必是指数级的增长

7， MH算法通过拒绝采样最终能生成平稳的马尔科夫链，但是有时因为拒绝概率太大导致状态转移频繁的被拒绝，算法效率低下。 吉布斯采样通过每次仅改变一个变量，其他变量保持不变的方法，使得每次改变仅在一个维度，不再拒绝，提升了效率。

8， 平均场假设 $q(z)=\prod_{i=1}^mq_i(z_i)$, 把多变量z拆分成一系列相互独立的变量组 $z_i$。
选择先验分布：参考变分推断
